# 0_Titanic
Este proyecto utiliza t√©cnicas de aprendizaje autom√°tico para predecir qu√© pasajeros del Titanic ten√≠an m√°s probabilidades de sobrevivir, basado en caracter√≠sticas como la edad, sexo, clase, n√∫mero de familiares a bordo, entre otros.
# Predicci√≥n de Supervivencia en el Titanic con Machine Learning

Este proyecto aplica t√©cnicas de machine learning para predecir qu√© pasajeros sobrevivieron al hundimiento del Titanic. Se han implementado m√∫ltiples modelos, an√°lisis comparativo y optimizaci√≥n para encontrar el mejor clasificador.

---

## Estructura del proyecto

- `notebooks/`
  - `0_titanic.ipynb` ‚Üí Notebook principal con todo el flujo de trabajo (EDA, preprocesado, modelado, evaluaci√≥n)
- `data/`
  - `train.csv` ‚Üí Datos de entrenamiento
  - `test.csv` ‚Üí Datos de test sin etiquetas
- `resultados/`
  - `submission_rf.csv` ‚Üí Predicci√≥n generada con el modelo Random Forest optimizado
  - `submission_histboost.csv` ‚Üí Predicci√≥n generada con el modelo HistGradientBoosting

---

## Objetivo del proyecto

Predecir la columna `Survived` (1 = sobrevivi√≥, 0 = no sobrevivi√≥) usando variables como clase, edad, sexo, tarifa, embarque, etc.

---

## Pasos seguidos

### üîπ 1. Limpieza y preprocesamiento
- Imputaci√≥n de `Age` con la mediana por `Sex` y `Pclass`
- Imputaci√≥n de `Fare` y `Embarked`
- Codificaci√≥n de variables categ√≥ricas (`Sex`, `Embarked`, `Title`, etc.)
- Creaci√≥n de nuevas features (`FamilySize`, `Title`, `IsAlone`)

### üîπ 2. Modelado
- Modelos evaluados:
  - `Logistic Regression`
  - `Random Forest`
  - `XGBoost`
  - `HistGradientBoostingClassifier`
- Evaluaci√≥n con `train_test_split`, `cross_val_score` y `cross_val_predict`
- Optimizaci√≥n de hiperpar√°metros con `GridSearchCV`
- Evaluaci√≥n por:
  - Accuracy
  - Precision, Recall, F1-score
  - Matriz de confusi√≥n
  - Curva ROC + AUC

---

## Resultados

| Modelo                       | Accuracy | Precision | Recall | F1 Score | AUC  |
|-----------------------------|----------|-----------|--------|----------|------|
| Logistic Regression         | 0.8156   | 0.7808    | 0.7703 | 0.7755   | 0.83 |
| Random Forest (GridSearch)  | 0.8324   | 0.8235    | 0.7568 | 0.7887   | 0.90 |
| HistGradientBoosting        | 0.8547   | 0.8429    | 0.7973 | 0.8194   | 0.91 ‚úÖ

 **Modelo seleccionado: HistGradientBoostingClassifier (base)**

---

## Curva ROC

Se compararon los mejores modelos visualmente:

- AUC Random Forest: **0.90**
- AUC HistGradientBoosting: **0.91**

---
